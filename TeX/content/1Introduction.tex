\section{Introduction}

As we read a piece of news or report, we often would like to know extra information about the news, probably the background, the recent progress or the other news on the same topic. Many online newspaper providers provide extended reading material after articles. ZEIT Online is a good example. The articles in the ZEIT Online, contain at the end of each article two hyperlinks to further articles that are on the same topic. Theses related articles enable the user to acquire more information of knowledge on the topic of interest. At the moment those articles are selected by the authors manually. However, this imposes several issues. First, there are about $400,000$ articles in the corpus. It is quite a challenge for the author to find the suitable articles from the tremendous corpus. Second, the author selects related articles normally immediately after the article is written. Therefore, the selected related articles must be released previously and be never updated once they are selected. The reader often exactly wants to obtain the recent information of the topic, after he reads a previous article. Third, the assignment of selection requires the knowledge of the topic and hence the knowledge base of the author have the important influence of the availability of the selection.

In this thesis, the kernel objective is to evaluate how such a process could be automated. In other words, we attempt to find an approach to replace the manual selection by a fully automated process. The first issue is how and why the author selects an articles as related to the target article. We do not know the exact process of human thinking.  However, we can consider the process simplified as a process of machine. Assume that a target article requires related articles. Every candidate article is compared with the target article and a score which refers to the probability of being related article is then computed. Finally, articles with the highest scores are selected as the related articles to the target. 

Each article in the ZEIT corpus is a semi-structured instance. One instance contains structured components which are called as meta-data, such as ``author'' and ``release time'', and unstructured components which are called as text fields, such as \ititle{} and \icontent{}. One issue of the research is how to make full use of such data to improve the system usability as much as possible. The most important field of an article is the text fields including \ititle{}, \isummary{} and \icontent{}. We cope with the text fields with Semantic Textual Similarity (STS) methods, e.g. Jaccard and \tfidf{}. The models of STS methods are learned from the entire corpus. After that, the text fields are transformed to structured data, such as vectors and the scores of similarity are then computed. The scores become the measure, such that all candidate articles are ordered and selected. The score is generated so far only by one STS method over one text field. The another issue is hence how to compute overall scores which are generated by the good combination of the components of articles. We consider the comparison between two articles as a set of comparisons between corresponding components of the articles. The relatedness between two articles is therefore represented as a series of scores. We use the supervised methods to treat the scores as features of an article-pair and compute the single output value as the relatedness score of the article-pair.

\clearpage

We now give the overview of the main content of the work as follows:
\begin{description}
    \item[Section 2] The term ``Semantic Textual Similarity (STS)'' is interpreted at first and several existing STS methods which belong to string-based algorithms and vector space models are introduced and their advantages and disadvantages are discussed. The three approaches of machine-learned ranking are summarized. In the end of the section, the research questions are formulated.
    \item[Section 3] The structures of ZEIT corpus and articles are described and the related-graph which illustrates the relationship of articles is defined. After understanding the structure of corpus, the task of the research and the evaluation methods are given. 
    \item[Section 4] First, the feasibility and challenge of the system are discussed. The architecture of the system is described. Then we design two experiments to evaluate the system in the static case and in the dynamic case, respectively. 
    \item[Section 5] The results of the both experiments are given and analysed in terms of effectiveness and efficiency. The best STS methods for every different text field of articles are selected by considering both of effectiveness and efficiency. In the end of this section, we discuss several types of false predictions by way of examples.
    \item[Section 6] In the experiments in section 5, only the STS methods are evaluated. In this section, we apply the supervised methods for improving the availability of the system. The supervised methods combine the scores of the STS methods over specific text fields and the relevance scores of meta-data. Finally, the system using logistic regression has the best precision of $63.4\%$.
    \item[Section 7] This section concludes the thesis with a summary and suggestions for future work.
\end{description}