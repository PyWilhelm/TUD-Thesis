\section{Introduction}

As we read a piece of news or report, we often would like to know extra information about the news, such as the background, the recent progress and the other news on the same topic. Many online newspaper providers provide extended reading material after articles, e.g. ZEIT Online. The articles in ZEIT Online contain at the end of each article two hyperlinks to further articles that are on the same topic. These related articles enable the user to acquire more information of knowledge on the topic of interest. At the moment the related articles are selected by the authors manually. However, this imposes several issues. First, there are about $400,000$ articles in the corpus. It is quite a challenge for authors to find suitable articles from the tremendous corpus. Second, authors select related articles normally immediately after the article is written. Therefore, the selected related articles must be released previously and be never updated once they are selected. Nevertheless, readers often exactly want to obtain the recent information of the topic, after reading a early article. Third, the assignment of selection requires the knowledge of the topic and hence the knowledge base of authors could have the important influence of the credibility of the selection.

In this thesis, the kernel objective is to evaluate how such a process could be automated. In other words, we attempt to find an approach to replace the manual selection by a fully automated process. The first issue is how and why the author selects an article as related to the target article. We do not know the exact process of human thinking.  However, we can consider the process simplified as a process of the machine. Assume that a target article requires related articles. Every candidate article is compared with the target article and a score which refers to the probability of being related article is then computed. Finally, articles with the highest scores are selected as the related articles to the target. 

Each article in the ZEIT corpus is a semi-structured instance. One instance contains structured components which are called as meta-data, such as ``author'' and ``release time'', and unstructured components which are called as text fields, such as \ititle{} and \icontent{}. One issue of the research is how to make full use of such data to improve the system usability as much as possible. The most important fields of an article are the text fields including \ititle{}, \isummary{} and \icontent{}. We cope with the text fields with \textit{Semantic Textual Similarity} (STS) methods, e.g. Jaccard and \tfidf{}. The models of STS methods are trained by the entire corpus. After that, the text fields are transformed to structured data, such as vectors, and the scores of similarity are then computed, such that all candidate articles are ordered and selected. The score is generated so far only by a single STS method over a single text field. Another issue is hence how to compute overall scores which are generated by the good combination of the components of articles. We consider the comparison between two articles as a set of comparisons between corresponding components of the articles. The relatedness between two articles is therefore represented as a series of scores. We use the supervised methods to treat the scores of different methods as features of a target-candidate pair and compute a single output value as the relatedness score of the target-candidate pair.

\clearpage

We now give the overview of the main content of the work as follows:
\begin{description}
    \item[Section 2] The term \textit{Semantic Textual Similarity} (STS) is interpreted at first and several existing STS methods which belong to string-based algorithms and vector space models are introduced, as well as their advantages and disadvantages are discussed. The three approaches of learning to rank are summarized. In the end of the section, the research questions are formulated.
    \item[Section 3] The structures of the ZEIT corpus and articles are described and the related-graph which illustrates the relationship of articles is defined. After understanding the structure of corpus, we give the task of the research and the evaluation methods. 
    \item[Section 4] The feasibility and challenge of the system are discussed at the beginning of the section. The architecture of the system is then described. We design two experiments to evaluate the system in the static case and in the dynamic case, respectively. 
    \item[Section 5] The results of the both experiments are given and analyzed in terms of effectiveness and efficiency. The best STS methods for every text field of articles are selected by considering both of effectiveness and efficiency. In the end of this section, we discuss several types of false predictions by way of examples.
    \item[Section 6] We apply supervised algorithms in the field of learning to rank for improving the usability of the system. The supervised algorithms combine the scores of the STS methods over specific text fields and the relevance scores of meta-data. Finally, the system using logistic regression has the best precision of $64.0\%$ in the static experiment and $53.4\%$ in the dynamic experiment.
    \item[Section 7] This section concludes the thesis with the answers to the research questions and the suggestions for future work.
\end{description}