\section{Conclusion}

The intention of this work is to design the system to discover related articles in a large corpus automatically and evaluate the performance and usability thereof. We use \textit{Semantic Textual Similarity} (STS) methods as the main methods to quantify the relatedness degree between two articles. After the algorithms being to evaluate are selected, the different text fields in articles are also to evaluate. Therefore, the basic configuration of the system is the combination of an algorithm and a (preprocessed over n-gram) text field. We evaluate the effectiveness and efficiency of systems. Effectiveness which includes \textit{precision@2@3} and \textit{nDCG} is the measure of the quality of the outputted results of systems. Efficiency is the measure of the cost of resource (e.g. operational time) during running of systems to discover related articles. 

We setup the experiments to test the performance of static and dynamic systems using different combination of algorithms and text fields. ``Static'' means the corpus of articles is constant during the experiment. ``Dynamic'' means the corpus keeps increasing in running of systems, that is to say, once a target article have ``obtained'' related articles from systems, it is inserted immediately into the corpus as candidates of potential related article for future articles. The static experiment is used for comparing the performance of different STS methods in different text fields and the dynamic experiment focuses on the influence of the increasing corpus on the performance of systems. 

All STS methods are unsupervised and document-based, and hence the labels of training data and the information in meta-data are not utilized. In the viewpoint of the supervised approach, it is regarded as an application of learning to rank in the field of Information Retrieval. Therefore, the algorithms on learning to rank, such as logistic regression and ListNet, are set up on the base of the existed system to make full use of all kinds of data including meta-data and STS scores as features and improve the usability of the system.


\subsection{Answer of Research Question}

In this part, we summarize this work by way of answering the research questions which are raised in section \ref{sec:2.5}. 

\paragraph{Can Semantic Text Similarity including string-based and vector space models methods be used for finding related articles? How effective and efficient is the metrics of performance, such as precision and operational time?}

The former sub-question can be answered positively in section \ref{sec:5.3}. The system using \tfidf{} in text field \icontent{} over unigram has the best effectiveness with \textit{precision@2@3} of $45.07\%$ (see figure \ref{fig:precision_2_3}) and the acceptable efficiency (figure \ref{fig:build_time} and \ref{fig:predict_time}). Finding related articles for one target costs on average $340ms$\footnote{}, if the time of system building is taken into account.  

\paragraph{How do the methods work in the practical scenario that the corpus keeps increasing with time? How is the performance of the incremental system different from a constant system? }

From the results of the second experiment which are reported in section \ref{sec:5.4}, the STS methods work also well in the increasing candidate corpus. The effectiveness is better than the so-called ``out-of-date'' controlled system which is never updated in running and meanwhile worse than the other so-called ``coverall'' controlled system which is trained by the historical articles and future articles. In terms of efficiency, the time cost of system updating and predicting also increases linearly during corpus increasing. 


\paragraph{Is it useful to combine the STS methods? Does it yield to an improvement in performance?}

The question could be answered relative negatively due to the results in section \ref{sec:6.4}. The effectiveness of combinations (\#1, \#2, \#3 and \#4) of the STS methods is slightly higher than the system using the best single STS method. Therefore, combing the STS methods cannot lead to a significant improvement in performance. 

\paragraph{The above introduced methods are unsupervised and ignore other meta-data. Does it lead to an improvement with utilizing supervised or semi-supervised algorithms which are proposed in the field of learning to rank?}

The question can be answered positively also in section \ref{sec:6.4}. Logistic regression with the feature set of meta-data and the best STS methods over unigram yields to the highest improvement in effectiveness. The \textit{precision@2@3} of this system is $64.0\%$ and improved by $20.0$ percent compared with the baseline in the static experiment. On the other hand, the final system has the average \textit{precision@2@3} of $53.38\%$ and outperforms the baseline by $15.86$ percent. 

\subsection{Application in Reality}
如果将系统实际使用，考虑到现在可以达到的准确率，无法实现完全自动化，可选取五个作为备选，然后人工选择，这一操作也可以大大提高准确率和减少工作量。


\begin{figure}[!htb]
    \centering
    \includegraphics[width=\textwidth]{fig/precision_inc_supervised_5}
    \caption[]{}
    \label{fig:top5}
\end{figure}

\subsection{Future Work}
首先说明系统设计中的lack，即存在比较大的bias，因为我们主观的将discover related articles的过程简化为计算STS并combine with meta-data relevance. 这个做法会产生较大的bias, errors are reported in section 5. Future work 是可以使用其他的附加方法，来减少或者消除bias，在更精确的同时，达到覆盖更恰当的范围。
